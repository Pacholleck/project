from urllib import request
import pandas
from bs4 import BeautifulSoup as BS
import re
import csv

url = 'http://urbandictionary.com'
links = []

for i in range(1,10+1):
    #print('page' + str(i))
    url = 'http://urbandictionary.com/?page=' + str(i)
    html = request.urlopen(url)
    bs = BS(html.read(), 'html.parser')

    tags = bs.findAll('a', {'class':'word text-denim font-bold font-serif dark:text-fluorescent break-words text-3xl md:text-[2.75rem] md:leading-10'}, href=re.compile('define.*'))

    links.extend(tags)

for link in links:
    print(link)
